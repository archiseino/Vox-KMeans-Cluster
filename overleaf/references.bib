@online{PasalDemokrasi,
    author    = {Kumparan},
    title     = {Isi Pasal 1 Ayat 2 UUD1945 Sebelum dan Sesudah Amandemen},
    date      = {Accessed 2024},
    url       = {https://kumparan.com/berita-terkini/isi-pasal-1-ayat-2-uud1945-sebelum-dan-sesudah-amandemen-1weOIUtUKWB},
}

@online{VisiMisiKPU,
    author    = {KPU},
    title     = {Visi dan Misi KPU},
    date      = {Accessed 2024},
    url       ={https://www.kpu.go.id/page/read/4/visi-dan-misi},
}


@online{InstrumenDpt,
    author    = {Komisi Pemilihan Umum},
    title     = {Pentingnya Daftar Pemilih Tetap yang Valid untuk Pemilu yang Demokratis},
    date      = {Accessed 2024},
    url       = {kpu.go.id},
}

@article{ImplementasiDataPemilihBerkelanjutan,
author = {Ointu, Lanny and Rotty, Viktory and Mamonto, Fitri},
year = {2022},
month = {11},
pages = {2969-2976},
title = {IMPLEMENTASI PROGRAM PEMUTAKHIRAN DATA PEMILIH BERKELANJUTAN DI KOTA MANADO},
volume = {1},
journal = {SIBATIK JOURNAL: Jurnal Ilmiah Bidang Sosial, Ekonomi, Budaya, Teknologi, dan Pendidikan},
doi = {10.54443/sibatik.v1i12.478}
}

@article{DataMiningTechniques,
author = {Han, Jiawei and Kamber, M.},
year = {2006},
month = {01},
pages = {},
title = {Data mining: concepts and techniques morgan kaufmann},
volume = {54}
}

@inproceedings{ClusteringMethod,
  title={Some methods for classification and analysis of multivariate observations},
  author={J. MacQueen},
  year={1967},
  url={https://api.semanticscholar.org/CorpusID:6278891}
}

@article{ElectionParticipation,
author = {Partheymüller, Julia and Mueller, Wolfgang C. and Rabitsch, Armin and Lidauer, Michael and Grohma, Paul},
year = {2022},
month = {05},
pages = {},
title = {Participation in the administration of elections and perceptions of electoral integrity},
volume = {77},
journal = {Electoral Studies},
doi = {10.1016/j.electstud.2022.102474}
}

@online{KpuDefinition,
    author    = {Annisa},
    title     = {Komisi Pemilihan Umum (KPU), Tugas dan Wewenangnya},
    date      = {Accessed 2024},
    url       = {Komisi Pemilihan Umum (KPU), Tugas dan Wewenangnya},
}

@inproceedings{KMeansDef,
  title={Some methods for classification and analysis of multivariate observations},
  author={Macqueen, J},
  booktitle={Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and Probability/University of California Press},
  year={1967}
}

@inproceedings{ElbowMethod,
author = {Umargono, Edy and Suseno, Jatmiko and Gunawan, S.K},
year = {2020},
month = {01},
pages = {},
title = {K-Means Clustering Optimization Using the Elbow Method and Early Centroid Determination Based on Mean and Median Formula},
doi = {10.2991/assehr.k.201010.019}
}

@article{DataClusteringAKJein,
author = {Jain, A. K. and Murty, M. N. and Flynn, P. J.},
title = {Data clustering: a review},
year = {1999},
issue_date = {Sept. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/331499.331504},
doi = {10.1145/331499.331504},
abstract = {Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview
of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify
 cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.},
journal = {ACM Comput. Surv.},
month = sep,
pages = {264–323},
numpages = {60},
keywords = {unsupervised learning, similarity indices, incremental clustering, exploratory data analysis, clustering applications, cluster analysis}
}

@article{ComparationMinMaxZScore,
	author = {Henderi Henderi and Tri Wahyuningsih and Efana Rahwanto},
	title = {Comparison of Min-Max normalization and Z-Score Normalization in the K-nearest neighbor (kNN) Algorithm to Test the Accuracy of Types of Breast Cancer},
	journal = {International Journal of Informatics and Information Systems},
	volume = {4},
	number = {1},
	year = {2021},
	keywords = {K-nearest neighbors; Min-Max Normalization; Z-Score Normalization; Breast Cancer},
	abstract = {The purpose of this study was to examine the results of the prediction of breast cancer, which have been classified based on two types of breast cancer, malignant and benign. The method used in this research is the k-NN algorithm with normalization of min-max and Z-score, the programming language used is the R language. The conclusion is that the highest k accuracy value is k = 5 and k = 21 with an accuracy rate of 98% in the normalization method using the min-max method. Whereas for the Z-score method the highest accuracy is at k = 5 and k = 15 with an accuracy rate of 97%. Thus the min-max normalization method in this study is considered better than the normalization method using the Z-score. The novelty of this research lies in the comparison between the two min-max normalizations and the Z-score normalization in the k-NN algorithm.},
	issn = {2579-7069},	pages = {13--20},	doi = {10.47738/ijiis.v4i1.73},
	url = {https://ijiis.org/index.php/IJIIS/article/view/73}
}

@article{PCAComponent,
  author    = {Michael Greenacre and Patrick J. F. Groenen and Trevor Hastie and Alfonso Iodice D’Enza and Angelos Markos and Elena Tuzhilina},
  title     = {Principal component analysis},
  journal   = {Nature Reviews Methods Primers},
  year      = {2022},
  volume    = {2},
  number    = {1},
  pages     = {100},
  doi       = {10.1038/s43586-022-00184-w},
  url       = {https://doi.org/10.1038/s43586-022-00184-w},
  abstract  = {Principal component analysis is a versatile statistical method for reducing a cases-by-variables data table to its essential features, called principal components. Principal components are a few linear combinations of the original variables that maximally explain the variance of all the variables. In the process, the method provides an approximation of the original data table using only these few major components. This Primer presents a comprehensive review of the method’s definition and geometry, as well as the interpretation of its numerical and graphical results. The main graphical result is often in the form of a biplot, using the major components to map the cases and adding the original variables to support the distance interpretation of the cases’ positions. Variants of the method are also treated, such as the analysis of grouped data, as well as the analysis of categorical data, known as correspondence analysis. Also described and illustrated are the latest innovative applications of principal component analysis: for estimating missing values in huge data matrices, sparse component estimation, and the analysis of images, shapes and functions. Supplementary material includes video animations and computer scripts in the R environment.},
  issn      = {2662-8449}
}
